# UserAssist: Understanding and controlling User-Assistant bias in LLMs

[![Datasets & Models](https://img.shields.io/badge/Datasets%20%26%20Models-HuggingFace-F59E0B?logo=huggingface&logoColor=white)](https://huggingface.co/datasets/UserAssist/UserAssist)


---

## Overview
  
This repository provides the full framework for:

- Benchmarking user assistant bias of commerical and open-weight models in frontier LLMs  
- Bidirectionally fine-tuning user assistant bias in open-weight LLMs and testing in realistic conversations

